{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfc19e21",
   "metadata": {
    "id": "-5KjQ8uX0jzI",
    "papermill": {
     "duration": 0.00974,
     "end_time": "2024-06-11T21:05:44.956491",
     "exception": false,
     "start_time": "2024-06-11T21:05:44.946751",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Machine Translation\n",
    "\n",
    "NLP - Spring Semester of 2024 at University of Tehran - CA5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1398972",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T21:05:44.977992Z",
     "iopub.status.busy": "2024-06-11T21:05:44.977302Z",
     "iopub.status.idle": "2024-06-11T21:07:38.099982Z",
     "shell.execute_reply": "2024-06-11T21:07:38.098906Z"
    },
    "id": "JbRDXM3B0jzM",
    "outputId": "f115a8f6-5fef-4e43-9451-ad5ff89d04dc",
    "papermill": {
     "duration": 113.135722,
     "end_time": "2024-06-11T21:07:38.102463",
     "exception": false,
     "start_time": "2024-06-11T21:05:44.966741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install fairseq\n",
    "!pip install sentencepiece\n",
    "!pip install sacremoses\n",
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d87d52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T21:07:38.137781Z",
     "iopub.status.busy": "2024-06-11T21:07:38.137455Z",
     "iopub.status.idle": "2024-06-11T21:07:38.958690Z",
     "shell.execute_reply": "2024-06-11T21:07:38.957384Z"
    },
    "id": "wMX8-_Fe0jzN",
    "papermill": {
     "duration": 0.842534,
     "end_time": "2024-06-11T21:07:38.961621",
     "exception": false,
     "start_time": "2024-06-11T21:07:38.119087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9afa4c",
   "metadata": {
    "id": "lUzEdKhg0jzO",
    "papermill": {
     "duration": 0.016344,
     "end_time": "2024-06-11T21:07:38.998481",
     "exception": false,
     "start_time": "2024-06-11T21:07:38.982137",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c365fa33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T21:07:39.032469Z",
     "iopub.status.busy": "2024-06-11T21:07:39.032073Z",
     "iopub.status.idle": "2024-06-11T21:07:44.009814Z",
     "shell.execute_reply": "2024-06-11T21:07:44.009059Z"
    },
    "id": "QYCcOO8t0jzO",
    "papermill": {
     "duration": 4.99755,
     "end_time": "2024-06-11T21:07:44.012161",
     "exception": false,
     "start_time": "2024-06-11T21:07:39.014611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_url = \"https://object.pouta.csc.fi/OPUS-MIZAN/v1/moses/en-fa.txt.zip\"\n",
    "dataset_file_name = \"moses_en-fa.zip\"\n",
    "\n",
    "urlretrieve(dataset_url, dataset_file_name)\n",
    "\n",
    "TEMP_DIR = 'temp'\n",
    "if not os.path.exists(TEMP_DIR):\n",
    "    os.mkdir(TEMP_DIR)\n",
    "\n",
    "with zipfile.ZipFile(dataset_file_name, 'r') as zip_file:\n",
    "    zip_file.extractall(TEMP_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c5d399",
   "metadata": {
    "id": "XBNnQQTM0jzP",
    "papermill": {
     "duration": 0.015846,
     "end_time": "2024-06-11T21:07:44.044745",
     "exception": false,
     "start_time": "2024-06-11T21:07:44.028899",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now that we have the file downloaded, we'll take a peek into it. Let's count the lines and see first 3 lines of each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d61b8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T21:07:44.077974Z",
     "iopub.status.busy": "2024-06-11T21:07:44.077650Z",
     "iopub.status.idle": "2024-06-11T21:07:45.272682Z",
     "shell.execute_reply": "2024-06-11T21:07:45.271594Z"
    },
    "id": "RzGsrIt70jzP",
    "outputId": "58cebd45-efcd-4854-860f-bd5f76ef06c1",
    "papermill": {
     "duration": 1.21435,
     "end_time": "2024-06-11T21:07:45.275077",
     "exception": false,
     "start_time": "2024-06-11T21:07:44.060727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ENGLISH_FILE = os.path.join(TEMP_DIR, \"MIZAN.en-fa.en\")\n",
    "PERSIAN_FILE = os.path.join(TEMP_DIR, \"MIZAN.en-fa.fa\")\n",
    "\n",
    "english_lines = []\n",
    "persian_lines = []\n",
    "\n",
    "with open(ENGLISH_FILE, 'r') as english_file:\n",
    "    english_lines = english_file.readlines()\n",
    "\n",
    "with open(PERSIAN_FILE, 'r') as persian_file:\n",
    "    persian_lines = persian_file.readlines()\n",
    "\n",
    "shutil.rmtree(TEMP_DIR, ignore_errors=True)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'english': english_lines,\n",
    "        'persian': persian_lines\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f'num of lines: {len(df)}')\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a854032",
   "metadata": {
    "id": "wxt-TSwM0jzQ",
    "papermill": {
     "duration": 0.016106,
     "end_time": "2024-06-11T21:07:45.307939",
     "exception": false,
     "start_time": "2024-06-11T21:07:45.291833",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now let's tokenize each line based on white spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864691b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T21:07:45.342096Z",
     "iopub.status.busy": "2024-06-11T21:07:45.341792Z",
     "iopub.status.idle": "2024-06-11T21:07:54.903789Z",
     "shell.execute_reply": "2024-06-11T21:07:54.902591Z"
    },
    "id": "vN4KTtXq0jzQ",
    "papermill": {
     "duration": 9.581981,
     "end_time": "2024-06-11T21:07:54.906294",
     "exception": false,
     "start_time": "2024-06-11T21:07:45.324313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['english_tokenized'] = df['english'].str.split()\n",
    "df['persian_tokenized'] = df['persian'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d66b5df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T21:07:54.940629Z",
     "iopub.status.busy": "2024-06-11T21:07:54.940353Z",
     "iopub.status.idle": "2024-06-11T21:07:58.237903Z",
     "shell.execute_reply": "2024-06-11T21:07:58.236902Z"
    },
    "id": "_Gqb3gCM0jzQ",
    "outputId": "edf6c75d-5572-4320-dee2-0f468a8c169e",
    "papermill": {
     "duration": 3.317693,
     "end_time": "2024-06-11T21:07:58.240675",
     "exception": false,
     "start_time": "2024-06-11T21:07:54.922982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['english_token_count'] = df['english_tokenized'].apply(len)\n",
    "df['persian_token_count'] = df['persian_tokenized'].apply(len)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df['english_token_count'], bins=range(1, max(df['english_token_count']) + 2), edgecolor='black')\n",
    "plt.xlabel('Token Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Token Count for English')\n",
    "plt.xticks(range(1, max(df['english_token_count']) + 2, 10))\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(df['persian_token_count'], bins=range(1, max(df['persian_token_count']) + 2), edgecolor='black')\n",
    "plt.xlabel('Token Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Token Count for Persian')\n",
    "plt.xticks(range(1, max(df['persian_token_count']) + 2, 10))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2dc74e",
   "metadata": {
    "id": "vwniE_Rf0jzR",
    "papermill": {
     "duration": 0.016573,
     "end_time": "2024-06-11T21:07:58.275917",
     "exception": false,
     "start_time": "2024-06-11T21:07:58.259344",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We have 1M lines which is a lot. We'll drop the ones that have less than 10 tokens or more than 50 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b08ea7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T21:07:58.311385Z",
     "iopub.status.busy": "2024-06-11T21:07:58.310638Z",
     "iopub.status.idle": "2024-06-11T21:07:58.645897Z",
     "shell.execute_reply": "2024-06-11T21:07:58.645014Z"
    },
    "id": "f9Kle-S50jzR",
    "papermill": {
     "duration": 0.355845,
     "end_time": "2024-06-11T21:07:58.648311",
     "exception": false,
     "start_time": "2024-06-11T21:07:58.292466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df[(df['persian_token_count'] >= 10) & (df['persian_token_count'] <= 50)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c11c24d",
   "metadata": {
    "id": "OT_F8BL_0jzS",
    "papermill": {
     "duration": 0.016649,
     "end_time": "2024-06-11T21:07:58.682532",
     "exception": false,
     "start_time": "2024-06-11T21:07:58.665883",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Create the train, test, eval splits and store them in separate files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119aad51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T21:07:58.717090Z",
     "iopub.status.busy": "2024-06-11T21:07:58.716816Z",
     "iopub.status.idle": "2024-06-11T21:08:04.970348Z",
     "shell.execute_reply": "2024-06-11T21:08:04.969479Z"
    },
    "id": "dk7PAoad0jzS",
    "papermill": {
     "duration": 6.273718,
     "end_time": "2024-06-11T21:08:04.972760",
     "exception": false,
     "start_time": "2024-06-11T21:07:58.699042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_TRAIN = 500000\n",
    "N_TEST = 10000\n",
    "N_EVAL = 5000\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "train_df = df[:N_TRAIN]\n",
    "test_df = df[N_TRAIN:N_TRAIN + N_TEST]\n",
    "eval_df = df[N_TRAIN + N_TEST:N_TRAIN + N_TEST+N_EVAL]\n",
    "\n",
    "SAVE_DIR = 'raw_data'\n",
    "if not os.path.exists(SAVE_DIR):\n",
    "    os.mkdir(SAVE_DIR)\n",
    "\n",
    "train_df['persian'].to_csv(os.path.join(SAVE_DIR, 'train.fa'))\n",
    "train_df['english'].to_csv(os.path.join(SAVE_DIR, 'train.en'))\n",
    "\n",
    "test_df['persian'].to_csv(os.path.join(SAVE_DIR, 'test.fa'))\n",
    "test_df['english'].to_csv(os.path.join(SAVE_DIR, 'test.en'))\n",
    "\n",
    "eval_df['persian'].to_csv(os.path.join(SAVE_DIR, 'valid.fa'))\n",
    "eval_df['english'].to_csv(os.path.join(SAVE_DIR, 'valid.en'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503d9ee5",
   "metadata": {
    "id": "PYgRPuyY0jzT",
    "papermill": {
     "duration": 0.016659,
     "end_time": "2024-06-11T21:08:05.007103",
     "exception": false,
     "start_time": "2024-06-11T21:08:04.990444",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training the Tokenizer and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cd0477",
   "metadata": {
    "id": "VQ2ug1Ru0jzT",
    "papermill": {
     "duration": 0.016732,
     "end_time": "2024-06-11T21:08:05.040487",
     "exception": false,
     "start_time": "2024-06-11T21:08:05.023755",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's use the sentencepiece command line tools to train our BPE model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09f599d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T21:08:05.075691Z",
     "iopub.status.busy": "2024-06-11T21:08:05.075397Z",
     "iopub.status.idle": "2024-06-11T21:08:50.488768Z",
     "shell.execute_reply": "2024-06-11T21:08:50.486182Z"
    },
    "id": "2GeURhpe0jzT",
    "papermill": {
     "duration": 45.452098,
     "end_time": "2024-06-11T21:08:50.509074",
     "exception": false,
     "start_time": "2024-06-11T21:08:05.056976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "PERSIAN_TOKENIZER_NAME = 'persian_bpe'\n",
    "if not os.path.exists(f'{PERSIAN_TOKENIZER_NAME}.model'):\n",
    "    spm.SentencePieceTrainer.train(\n",
    "        input=os.path.join(SAVE_DIR, 'train.fa'),\n",
    "        model_prefix=PERSIAN_TOKENIZER_NAME,\n",
    "        vocab_size=10000,\n",
    "        model_type='bpe'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dae06b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T21:08:50.546516Z",
     "iopub.status.busy": "2024-06-11T21:08:50.546204Z",
     "iopub.status.idle": "2024-06-11T21:09:33.773656Z",
     "shell.execute_reply": "2024-06-11T21:09:33.768574Z"
    },
    "id": "Iz4hBaAt0jzU",
    "papermill": {
     "duration": 43.271935,
     "end_time": "2024-06-11T21:09:33.798407",
     "exception": false,
     "start_time": "2024-06-11T21:08:50.526472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ENGLISH_TOKENIZER_NAME = 'english_bpe'\n",
    "if not os.path.exists(f'{ENGLISH_TOKENIZER_NAME}.model'):\n",
    "    spm.SentencePieceTrainer.train(\n",
    "        input=os.path.join(SAVE_DIR, 'train.en'),\n",
    "        model_prefix=ENGLISH_TOKENIZER_NAME,\n",
    "        vocab_size=10000,\n",
    "        model_type='bpe'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a26dd1",
   "metadata": {
    "id": "m9KVAMKk0jzU",
    "papermill": {
     "duration": 0.019492,
     "end_time": "2024-06-11T21:09:33.839004",
     "exception": false,
     "start_time": "2024-06-11T21:09:33.819512",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Use the trained model to tokenize the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb849a7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T21:09:33.881185Z",
     "iopub.status.busy": "2024-06-11T21:09:33.880870Z",
     "iopub.status.idle": "2024-06-11T21:09:33.904576Z",
     "shell.execute_reply": "2024-06-11T21:09:33.903548Z"
    },
    "id": "0t_Djb4T0jzU",
    "outputId": "81970193-db1b-4fd1-f8a7-8aefe9ebf7cc",
    "papermill": {
     "duration": 0.04826,
     "end_time": "2024-06-11T21:09:33.906748",
     "exception": false,
     "start_time": "2024-06-11T21:09:33.858488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "persian_tokenizer = spm.SentencePieceProcessor()\n",
    "persian_tokenizer.load('persian_bpe.model')\n",
    "\n",
    "print(persian_tokenizer.encode_as_pieces('سلام به دنیای پردازش زبان طبیعی!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88b4052",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T21:09:33.991161Z",
     "iopub.status.busy": "2024-06-11T21:09:33.990838Z",
     "iopub.status.idle": "2024-06-11T21:09:34.004440Z",
     "shell.execute_reply": "2024-06-11T21:09:34.003476Z"
    },
    "id": "lN2EVGlh0jzU",
    "outputId": "d9f27fbf-2326-4e47-fb9c-6864aa5d39bd",
    "papermill": {
     "duration": 0.037301,
     "end_time": "2024-06-11T21:09:34.006576",
     "exception": false,
     "start_time": "2024-06-11T21:09:33.969275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "english_tokenizer = spm.SentencePieceProcessor()\n",
    "english_tokenizer.load('english_bpe.model')\n",
    "\n",
    "print(english_tokenizer.encode_as_pieces('Hello Natural Language Processing world!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7da894",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T21:09:34.048490Z",
     "iopub.status.busy": "2024-06-11T21:09:34.048204Z",
     "iopub.status.idle": "2024-06-11T21:10:55.326485Z",
     "shell.execute_reply": "2024-06-11T21:10:55.325607Z"
    },
    "id": "NnIYdPA30jzV",
    "outputId": "115acf7c-4aeb-4d6a-a5f7-9086599b8042",
    "papermill": {
     "duration": 81.30201,
     "end_time": "2024-06-11T21:10:55.329117",
     "exception": false,
     "start_time": "2024-06-11T21:09:34.027107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df['persian_tokenized'] = train_df['persian'].apply(persian_tokenizer.encode_as_pieces)\n",
    "test_df['persian_tokenized'] = test_df['persian'].apply(persian_tokenizer.encode_as_pieces)\n",
    "eval_df['persian_tokenized'] = eval_df['persian'].apply(persian_tokenizer.encode_as_pieces)\n",
    "\n",
    "train_df['english_tokenized'] = train_df['english'].apply(persian_tokenizer.encode_as_pieces)\n",
    "test_df['english_tokenized'] = test_df['english'].apply(persian_tokenizer.encode_as_pieces)\n",
    "eval_df['english_tokenized'] = eval_df['english'].apply(persian_tokenizer.encode_as_pieces)\n",
    "\n",
    "TOKENIZED_DIR = 'tokenized_data'\n",
    "if not os.path.exists(TOKENIZED_DIR):\n",
    "    os.mkdir(TOKENIZED_DIR)\n",
    "\n",
    "train_df['persian_tokenized'].to_csv(os.path.join(TOKENIZED_DIR, 'train.fa'))\n",
    "train_df['english_tokenized'].to_csv(os.path.join(TOKENIZED_DIR, 'train.en'))\n",
    "\n",
    "test_df['persian_tokenized'].to_csv(os.path.join(TOKENIZED_DIR, 'test.fa'))\n",
    "test_df['english_tokenized'].to_csv(os.path.join(TOKENIZED_DIR, 'test.en'))\n",
    "\n",
    "eval_df['persian_tokenized'].to_csv(os.path.join(TOKENIZED_DIR, 'valid.fa'))\n",
    "eval_df['english_tokenized'].to_csv(os.path.join(TOKENIZED_DIR, 'valid.en'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d566dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T21:10:55.372691Z",
     "iopub.status.busy": "2024-06-11T21:10:55.372393Z",
     "iopub.status.idle": "2024-06-11T21:14:42.047747Z",
     "shell.execute_reply": "2024-06-11T21:14:42.046488Z"
    },
    "id": "8qGSxu2b1-ct",
    "outputId": "0e9d9f75-1e73-493a-dd1a-d216a8dfaf76",
    "papermill": {
     "duration": 226.699747,
     "end_time": "2024-06-11T21:14:42.050421",
     "exception": false,
     "start_time": "2024-06-11T21:10:55.350674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!fairseq-preprocess --source-lang en --target-lang fa \\\n",
    "  --trainpref tokenized_data/train --validpref tokenized_data/valid --testpref tokenized_data/test \\\n",
    "  --destdir data-bin --workers 20 \\\n",
    "  --nwordssrc 10000 --nwordstgt 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bd98cb",
   "metadata": {
    "papermill": {
     "duration": 0.022743,
     "end_time": "2024-06-11T21:14:42.095702",
     "exception": false,
     "start_time": "2024-06-11T21:14:42.072959",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training LSTM Encoder-Decoder model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de6e6b5",
   "metadata": {
    "papermill": {
     "duration": 0.020624,
     "end_time": "2024-06-11T21:14:42.139215",
     "exception": false,
     "start_time": "2024-06-11T21:14:42.118591",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now that we have our data preprocessed and ready, let's train out lstm encoder-decoder model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd46b9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T21:14:42.182826Z",
     "iopub.status.busy": "2024-06-11T21:14:42.182429Z",
     "iopub.status.idle": "2024-06-11T23:08:07.351341Z",
     "shell.execute_reply": "2024-06-11T23:08:07.350319Z"
    },
    "papermill": {
     "duration": 6805.194317,
     "end_time": "2024-06-11T23:08:07.353993",
     "exception": false,
     "start_time": "2024-06-11T21:14:42.159676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!fairseq-train data-bin \\\n",
    "  --arch lstm --encoder-bidirectional \\\n",
    "  --encoder-layers 6 --decoder-layers 6 \\\n",
    "  --optimizer adam --adam-betas '(0.9, 0.98)' --lr 0.001 \\\n",
    "  --max-tokens 4000 \\\n",
    "  --criterion label_smoothed_cross_entropy --label-smoothing 0.2 \\\n",
    "  --save-dir checkpoints/lstm \\\n",
    "  --tensorboard-logdir logs/lstm \\\n",
    "  --max-epoch 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe2d395",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T23:08:10.248700Z",
     "iopub.status.busy": "2024-06-11T23:08:10.248331Z",
     "iopub.status.idle": "2024-06-11T23:09:36.454696Z",
     "shell.execute_reply": "2024-06-11T23:09:36.453626Z"
    },
    "papermill": {
     "duration": 87.290498,
     "end_time": "2024-06-11T23:09:36.457348",
     "exception": false,
     "start_time": "2024-06-11T23:08:09.166850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!fairseq-train data-bin \\\n",
    "  --arch transformer --encoder-layers 6 --decoder-layers 6 \\\n",
    "  --optimizer sgd --momentum 0.99 --nesterov --lr 0.001 \\\n",
    "  --max-tokens 4000 \\\n",
    "  --criterion label_smoothed_cross_entropy --label-smoothing 0.2 \\\n",
    "  --save-dir checkpoints/transformer \\\n",
    "  --tensorboard-logdir logs/transformer \\\n",
    "  --max-epoch 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80620654",
   "metadata": {
    "papermill": {
     "duration": 1.062652,
     "end_time": "2024-06-11T23:09:38.522466",
     "exception": false,
     "start_time": "2024-06-11T23:09:37.459814",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Qualifying and Testing the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6a6a3d",
   "metadata": {
    "papermill": {
     "duration": 1.003665,
     "end_time": "2024-06-11T23:09:40.558219",
     "exception": false,
     "start_time": "2024-06-11T23:09:39.554554",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Use `fairseq-generate` to get test results of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18b553a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T23:09:42.629221Z",
     "iopub.status.busy": "2024-06-11T23:09:42.628794Z",
     "iopub.status.idle": "2024-06-11T23:12:41.864425Z",
     "shell.execute_reply": "2024-06-11T23:12:41.863221Z"
    },
    "papermill": {
     "duration": 180.242228,
     "end_time": "2024-06-11T23:12:41.867070",
     "exception": false,
     "start_time": "2024-06-11T23:09:41.624842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!fairseq-generate data-bin \\\n",
    "  --path checkpoints/lstm/checkpoint_best.pt \\\n",
    "  --beam 5 \\\n",
    "  --batch-size 32 \\\n",
    "  --remove-bpe > lstm-result.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dd56c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T23:12:44.033298Z",
     "iopub.status.busy": "2024-06-11T23:12:44.031973Z",
     "iopub.status.idle": "2024-06-11T23:13:12.528935Z",
     "shell.execute_reply": "2024-06-11T23:13:12.527752Z"
    },
    "papermill": {
     "duration": 29.640216,
     "end_time": "2024-06-11T23:13:12.531456",
     "exception": false,
     "start_time": "2024-06-11T23:12:42.891240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!fairseq-generate data-bin \\\n",
    "  --path checkpoints/transformer/checkpoint_best.pt \\\n",
    "  --beam 5 \\\n",
    "  --batch-size 32 \\\n",
    "  --remove-bpe > transformer-result.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53c3107",
   "metadata": {
    "papermill": {
     "duration": 1.035958,
     "end_time": "2024-06-11T23:13:14.621442",
     "exception": false,
     "start_time": "2024-06-11T23:13:13.585484",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We'll also use `unbabel-comet` to show the comet metric on out trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a9249b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T23:13:16.798501Z",
     "iopub.status.busy": "2024-06-11T23:13:16.798097Z",
     "iopub.status.idle": "2024-06-11T23:13:33.902894Z",
     "shell.execute_reply": "2024-06-11T23:13:33.901853Z"
    },
    "papermill": {
     "duration": 18.135503,
     "end_time": "2024-06-11T23:13:33.905387",
     "exception": false,
     "start_time": "2024-06-11T23:13:15.769884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install unbabel-comet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3488057",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T23:13:36.032016Z",
     "iopub.status.busy": "2024-06-11T23:13:36.031674Z",
     "iopub.status.idle": "2024-06-11T23:13:36.039735Z",
     "shell.execute_reply": "2024-06-11T23:13:36.038779Z"
    },
    "papermill": {
     "duration": 1.037629,
     "end_time": "2024-06-11T23:13:36.041867",
     "exception": false,
     "start_time": "2024-06-11T23:13:35.004238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_hypotheses(fairseq_output_file, hypothesis_file, source_file, target_file):\n",
    "    with open(fairseq_output_file, 'r') as infile, open(hypothesis_file, 'w') as hypothesis, open(source_file, 'w') as source, open(target_file, 'w') as target:\n",
    "        for line in infile:\n",
    "            if line.startswith('H-'):\n",
    "                hypothesis_line = line.split('\\t')[2]\n",
    "                hypothesis.write(hypothesis_line)\n",
    "            elif line.startswith('S-'):\n",
    "                source_line = line.split('\\t')[1]\n",
    "                source.write(source_line)\n",
    "            elif line.startswith('T-'):\n",
    "                target_line = line.split('\\t')[1]\n",
    "                target.write(target_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eec4dc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T23:13:38.170515Z",
     "iopub.status.busy": "2024-06-11T23:13:38.170127Z",
     "iopub.status.idle": "2024-06-11T23:13:38.294790Z",
     "shell.execute_reply": "2024-06-11T23:13:38.293951Z"
    },
    "papermill": {
     "duration": 1.155385,
     "end_time": "2024-06-11T23:13:38.296923",
     "exception": false,
     "start_time": "2024-06-11T23:13:37.141538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "extract_hypotheses('lstm-result.txt', 'lstm-hypothesis.txt', 'lstm-source.txt', 'lstm-target.txt')\n",
    "extract_hypotheses('transformer-result.txt', 'transformer-hypothesis.txt', 'transformer-source.txt', 'transformer-target.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af213ed3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-11T23:13:40.487190Z",
     "iopub.status.busy": "2024-06-11T23:13:40.486811Z",
     "iopub.status.idle": "2024-06-11T23:28:45.669900Z",
     "shell.execute_reply": "2024-06-11T23:28:45.668619Z"
    },
    "papermill": {
     "duration": 906.294802,
     "end_time": "2024-06-11T23:28:45.672650",
     "exception": false,
     "start_time": "2024-06-11T23:13:39.377848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!comet-score -s lstm-source.txt -t lstm-hypothesis.txt -r lstm-target.txt\n",
    "!comet-score -s transformer-source.txt -t transformer-hypothesis.txt -r transformer-target.txt"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8587.694961,
   "end_time": "2024-06-11T23:28:49.740206",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-11T21:05:42.045245",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
